# app/search_core.py
import os, json
import numpy as np
import re
from rank_bm25 import BM25Okapi


# ä¸ºäº†ç»“æœç¨³å®šï¼Œé»˜è®¤ä¼˜å…ˆç¦»çº¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹ï¼ˆå¦‚æœæƒ³è”ç½‘ï¼Œåˆ æ‰ä¸‹é¢ä¸¤è¡Œï¼‰
os.environ.setdefault("TRANSFORMERS_OFFLINE", "1")
os.environ.setdefault("HF_HUB_OFFLINE", "1")

EMB_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

_WORD = re.compile(r"\w+", re.U)
def _tok(s: str):
    # ç®€å•è‹±æ–‡ token åˆ‡åˆ†ï¼›åé¢å¦‚æœå«ä¸­æ–‡å†æ¢åˆ†è¯å™¨
    return _WORD.findall((s or "").lower())

def _minmax(a: np.ndarray):
    if a.size == 0: return a
    mn, mx = float(a.min()), float(a.max())
    return (a - mn) / (mx - mn + 1e-9) if mx > mn else np.zeros_like(a)

def l2_normalize(x: np.ndarray) -> np.ndarray:
    n = (x ** 2).sum(axis=1, keepdims=True) ** 0.5 + 1e-12
    return x / n

class Searcher:
    """
    è´Ÿè´£ï¼šåŠ è½½æ¨¡å‹/ç´¢å¼•/å…ƒæ•°æ® & æ‰§è¡Œä¸€æ¬¡æŸ¥è¯¢
    ç”¨æ³•ï¼š
        s = Searcher("./cache/vectors.faiss", "./cache/meta.jsonl")
        results = s.search("wheel speed sensor", topk=5, section="both")
    """
    def __init__(self, faiss_path: str, meta_path: str, model_name: str = EMB_MODEL):
        from sentence_transformers import SentenceTransformer
        import faiss

        self.model = SentenceTransformer(model_name)
        self.index = faiss.read_index(faiss_path)

  # ğŸ‘‡ æ–°å¢ï¼šè®°å½•æ˜¯å¦æ˜¯ Inner Product ç´¢å¼•
        self._is_ip = hasattr(self.index, "metric_type") and \
                    (self.index.metric_type == faiss.METRIC_INNER_PRODUCT)

        # è¯» meta.jsonlï¼ˆä¸å‘é‡é¡ºåºä¸€ä¸€å¯¹åº”ï¼‰
        with open(meta_path, "r", encoding="utf-8") as f:
            self.meta_lines = f.readlines()  # 31k è¡Œä½“é‡ä¸å¤§ï¼Œç›´æ¥æ”¾å†…å­˜
        
        # ====== æ–°å¢ï¼šæŠŠæ¯æ¡æ–‡æ¡£çš„å¯æ£€ç´¢æ–‡æœ¬å–å‡ºæ¥ï¼ˆç”¨äº BM25ï¼‰======
        # ç”¨ text å­—æ®µ
        self._docs_texts = []
        for line in self.meta_lines:
            m = json.loads(line)
            # è¿™é‡Œç”¨ä½ å·²æœ‰çš„å­—æ®µï¼Œä¿æŒå’Œå‘é‡ç´¢å¼•æ—¶çš„ä¸€è‡´æ€§
            self._docs_texts.append((m.get("text") or ""))

        # ====== æ–°å¢ï¼šåˆå§‹åŒ– BM25 ======
        self._doc_tokens = [_tok(t) for t in self._docs_texts]
        self._bm25 = BM25Okapi(self._doc_tokens)   # é»˜è®¤å‚æ•° k1/b å³å¯


    def encode_query(self, query: str) -> np.ndarray:
        v = self.model.encode([query], convert_to_numpy=True).astype("float32")
        return l2_normalize(v)
    
    def vector_topn(self, query: str, topn: int = 200):
        """
        è¿”å› [(doc_idx, sim)]ï¼Œsim è¶Šå¤§è¶Šç›¸å…³
        """
        q = self.encode_query(query)
        D, I = self.index.search(q, topn)  # D: è·ç¦»æˆ–ç›¸ä¼¼åº¦ï¼›I: ç´¢å¼•
        D, I = D[0], I[0]

        # å°† D ç»Ÿä¸€è½¬ä¸ºâ€œè¶Šå¤§è¶Šå¥½â€
        # ç»éªŒï¼šè‹¥æ˜¯ L2 ç´¢å¼• â†’ å€¼è¶Šå°è¶Šè¿‘ï¼›è½¬æ¢ä¸º sim = 1/(1+d)
        # è‹¥æ˜¯ IP ç´¢å¼• â†’ å·²ç»æ˜¯ç›¸ä¼¼åº¦ï¼›æ­¤è½¬æ¢ä¹Ÿå¯ç”¨ï¼Œä¸ä¼šå‡ºé”™ï¼ˆåªæ˜¯å•è°ƒæ˜ å°„ï¼‰
        # ğŸ‘‡åŒºåˆ†ä¸¤ç§åº¦é‡
        if self._is_ip:
            # IPï¼šD æœ¬èº«å°±æ˜¯â€œè¶Šå¤§è¶Šå¥½â€çš„ç›¸ä¼¼åº¦
            sims = D
        else:
            # L2ï¼šD æ˜¯è·ç¦»ï¼Œè¶Šå°è¶Šè¿‘ â†’ è½¬æˆâ€œè¶Šå¤§è¶Šå¥½â€çš„ç›¸ä¼¼åº¦
            sims = 1.0 / (1.0 + D)
        return [(int(i), float(s)) for i, s in zip(I, sims) if int(i) >= 0]

    def bm25_topn(self, query: str, candidate_ids: list[int] | None = None, topn: int = 200):
            """
            ä»… BM25 çš„æ£€ç´¢ï¼šè¿”å› [(doc_idx, bm25_score)]ï¼Œscore è¶Šå¤§è¶Šç›¸å…³
            - candidate_ids: å¯é€‰çš„å€™é€‰é›†åˆï¼ˆä¼ å…¥åˆ™åªåœ¨è¯¥é›†åˆé‡Œæ‰“åˆ†ï¼›ä¸ä¼ åˆ™å…¨é‡ï¼‰
            """
            assert self._bm25 is not None, "BM25 is not initialized."
            qtok = _tok(query)

            scores_full = self._bm25.get_scores(qtok)  # å¯¹å…¨é‡æ–‡æ¡£æ‰“åˆ†
            if candidate_ids is None:
                pairs = [(i, float(scores_full[i])) for i in range(len(scores_full))]
            else:
                pairs = [(i, float(scores_full[i])) for i in candidate_ids]

            pairs.sort(key=lambda x: x[1], reverse=True)
            return pairs[:topn]

    def hybrid_topk(self, query: str, topk: int = 10, bm25_weight: float = 0.5,
                    candidate_ids: list[int] | None = None,
                    bm25_M: int = 200, vec_N: int = 200):
        """
        æ··åˆæ£€ç´¢ï¼šçº¿æ€§èåˆ  final = alpha * bm25_norm + (1-alpha) * vec_norm
        è¿”å› [(idx, final_score)]
        """
        # 1) ä¸¤è·¯åˆ†æ•°
        bm25_pairs = self.bm25_topn(query, candidate_ids=candidate_ids, topn=bm25_M)
        vec_pairs  = self.vector_topn(query, topn=vec_N)

        bm25_map = {i: s for i, s in bm25_pairs}
        vec_map  = {i: s for i, s in vec_pairs}

        # 2) å€™é€‰é›†åˆ = ä¸¤è·¯å¹¶é›†
        cand = list(set(bm25_map.keys()) | set(vec_map.keys()))
        if not cand:
            return []

        bm_vals = np.array([bm25_map.get(i, 0.0) for i in cand], dtype=float)
        vc_vals = np.array([vec_map.get(i, 0.0) for i in cand], dtype=float)

        bm_n = _minmax(bm_vals)
        vc_n = _minmax(vc_vals)

        alpha = float(bm25_weight)
        final = alpha * bm_n + (1.0 - alpha) * vc_n

        ranked = sorted(zip(cand, final), key=lambda x: x[1], reverse=True)[:topk]
        return ranked


    def _format_by_idxs(self, idx_score_pairs):
        out = []
        for i, s in idx_score_pairs:
            m = json.loads(self.meta_lines[i])
            text_full = (m.get("text") or "")           # âœ… å…ˆå–å…¨æ–‡
            snippet = text_full[:200].replace("\n", " ")# âœ… å†åšæ‘˜è¦
            out.append({
                "score": float(s),
                "section": m["section"],
                "title": m["title"],
                "doc_number": m["doc_number"],
                "classification": m.get("classification", ""),
                "idx": int(m["idx"]),
                "snippet": snippet,
                "text_full": text_full,                 # âœ… ç°åœ¨å˜é‡å·²å­˜åœ¨
            })
        return out

    def search(self, query: str, topk: int = 5, section: str = "both", cpc_prefix: str | None = None):
        """
        è¿”å›ï¼šlist[dict]ï¼Œæ¯æ¡åŒ…å« score/section/title/doc_number/classification/idx/snippet
        """
        q = self.encode_query(query)

        # å…ˆå¤šå–ä¸€äº›å€™é€‰ï¼Œåé¢å†è¿‡æ»¤ï¼ˆä¿è¯æœ‰è¶³å¤Ÿç»“æœï¼‰
        K = max(topk * 5, topk)
        scores, idxs = self.index.search(q, K)
        scores, idxs = scores[0].tolist(), idxs[0].tolist()

        out = []
        for s, i in zip(scores, idxs):
            if i < 0:
                continue
            m = json.loads(self.meta_lines[i])

            # section è¿‡æ»¤
            if section in ("claim", "desc") and m["section"] != section:
                continue

            # cpc å‰ç¼€è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
            if cpc_prefix:
                cpc = (m.get("classification") or "").upper()
                if not cpc.startswith(cpc_prefix.upper()):
                    continue

            text_full = (m.get("text") or "")
            snippet = text_full[:200].replace("\n", " ")
            out.append({
                "score": float(s),
                "section": m["section"],
                "title": m["title"],
                "doc_number": m["doc_number"],
                "classification": m.get("classification", ""),
                "idx": int(m["idx"]),
                "snippet": snippet,
                "text_full": text_full,   # âœ… æ–°å¢
            })
            if len(out) >= topk:
                break

            # å¦‚æœè¿‡æ»¤å¤ªä¸¥æ ¼å¯¼è‡´ä¸å¤Ÿ topkï¼Œå¯ä»¥åœ¨è¿™é‡Œè€ƒè™‘â€œè¡¥é½â€é€»è¾‘ï¼ˆå…ˆä¸åšï¼Œä¿æŒç®€å•ï¼‰
        return out
  
    def search_hybrid(self, query: str, topk: int = 5, bm25_weight: float = 0.5,
                      section: str = "both", cpc_prefix: str | None = None):
        """
        æ··åˆæ£€ç´¢ + CPC/section è¿‡æ»¤
        è¿”å›ä¸ self.search ç›¸åŒç»“æ„çš„åˆ—è¡¨
        """
        # 1) æ„å»ºå€™é€‰é›†åˆï¼ˆå…ˆæŒ‰ CPC/section è¿‡æ»¤ï¼‰
        candidate_ids = []
        prefix = (cpc_prefix or "").upper()
        for i, line in enumerate(self.meta_lines):
            m = json.loads(line)

            # section è¿‡æ»¤
            if section in ("claim", "desc") and m["section"] != section:
                continue

            # CPC å‰ç¼€è¿‡æ»¤
            if prefix:
                cpc = (m.get("classification") or "").upper()
                if not cpc.startswith(prefix):
                    continue

            candidate_ids.append(i)

        if not candidate_ids:
            # æ²¡æœ‰å€™é€‰åˆ™å›é€€å…¨é‡
            candidate_ids = None

        # 2) æ··åˆèåˆ
        ranked = self.hybrid_topk(query, topk=topk, bm25_weight=bm25_weight,
                                  candidate_ids=candidate_ids)

        # 3) æ ¼å¼åŒ–è¾“å‡º
        return self._format_by_idxs(ranked)


